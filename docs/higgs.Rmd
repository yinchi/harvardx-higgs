--- 
title: 'HarvardX 125.9x Project: Higgs dataset classification'
author: "Firstname Lastname"
date: "`r Sys.Date()`"
documentclass: article
mainfont: Times New Roman
monofont: Fira Code
geometry: margin=2.5cm
bibliography: book.bib
biblio-style: acm
description: |
  See also: _output.yml, _bookdown.yml
link-citations: yes
site: bookdown::bookdown_site
---

# Preface {-}

This template generates output in both [HTML](index.html) and [PDF](higgs.pdf) form.
Code chunks are typeset in 
[Fira Code](https://github.com/tonsky/FiraCode), with code ligatures enabled.

## R setup

```{r Setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  dpi = 144
)

# Shrink code font size relative to main text in PDF output
# https://stackoverflow.com/questions/25646333/#46526740
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
if (knitr::is_latex_output()) {
  knitr::knit_hooks$set(chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    paste0("\n \\", "small","\n\n", x, "\n\n \\normalsize")
  })
}
```

```{r Load-libraries}

# R 4.1 key features: new pipe operator, \(x) as shortcut for function(x)
# R 4.0 key features: stringsAsFactors = FALSE by default, raw character strings r"()"
if (packageVersion('base') < '4.1.0') {
  stop('This code requires R >= 4.1.0!')
}

if(!require("pacman")) install.packages("pacman")
library(pacman)
p_load(data.table, dtplyr, tidyverse, R.utils, Rfast,
       lightgbm, keras, caret, pROC, knitr, conflicted)
conflict_prefer('summarize', 'dplyr')
conflict_prefer('summarise', 'dplyr')
conflict_prefer('filter', 'dplyr')
conflict_prefer('between', 'dplyr')
conflict_prefer('auc', 'pROC')

if(!is_keras_available()) install_keras()

# Somehow, this seems to prevent memory leaks
tensorflow::tf$compat$v1$disable_eager_execution()
```

<!--chapter:end:index.Rmd-->

# Introduction

This report partially fufills the requirements for the HarvardX course PH125.9x:
"Data Science: Capstone". The objective of this project is to apply machine learning techniques
beyond standard linear regression to a publicly available dataset of choice.

## The HIGGS dataset

The [HIGGS dataset](https://archive.ics.uci.edu/ml/datasets/HIGGS#) is a synthetic dataset
simulating particle accelerator data [@Baldi_2014]. Although the details of the simulated
particle collisions are beyond the scope of this project, We summarize the contents of the
dataset as follows.

The HIGGS dataset is available from the UCI Machine Learning Repository.
The following code loads the dataset, downloading and unzipping the CSV file as necessary:

```{r Download-data, results='hide'}
options(timeout=1800) # Give more time for the download to complete
if(!file.exists('data_raw/HIGGS.csv')) {
  download.file(
    'https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz',
    'data_raw/HIGGS.csv.gz')
  gunzip('data_raw/HIGGS.csv.gz')
}
```
```{r Load-Data}

# Load dataset into memory
higgs_all <- fread('data_raw/HIGGS.csv')

# Assign column names (csv contains no headers)
colnames(higgs_all) <- c('signal',
                     'lepton_pT', 'lepton_eta', 'lepton_phi',
                     'missing_E_mag', 'missing_E_phi',
                     'jet1_pT', 'jet1_eta', 'jet1_phi', 'jet1_btag',
                     'jet2_pT', 'jet2_eta', 'jet2_phi', 'jet2_btag',
                     'jet3_pT', 'jet3_eta', 'jet3_phi', 'jet3_btag',
                     'jet4_pT', 'jet4_eta', 'jet4_phi', 'jet4_btag',
                     'm_jj', 'm_jjj', 'm_lv', 'm_jlv',
                     'm_bb', 'm_wbb', 'm_wwbb')

# Separate input and output columns
xAll <- higgs_all %>% select(-signal) %>% as.data.table()
yAll <- higgs_all %>% select(signal) %>% as.data.table()
rm(higgs_all)
```

The HIGGS dataset contains `r ncol(xAll)` features and one binary target, `signal`. The
`signal` value of an observation corresponds to whether a particle collision produced a Higgs
boson as an intermediate product. Two possible processes are considered with the same input
particles, one of which generates the Higgs boson (the "signal" process) and one which does not
(the "background" process).

Of the `r ncol(xAll)` features in the dataset, the last seven features, prefixed '`m_`', are called
"high-level" features and are based on computing the mass of expected intermediate decay products
in the signal and background processes, assuming that the observed final decay products were
generated by each process.  The 21 "low-level" features consist of momentum data for a lepton
and four jets, *b*-tags for each jet marking the likelihood that the jet is associated with a
bottom quark, and partial information of "missing" total momentum caused by undetected decay
products such as neutrinos.  Due to the nature of the simulated particle colliders and detectors,
full directional data of this missing momentum is not available.

## Creating the final test splits

Since `Keras`, one of the libraries we will use, uses "validation" internally when fitting
a model, we will use the term "**final** validation set" to denote the final hold-out set for
post-model evaluation.

```{r Create-splits, results='hide'}

# Create 10% test set split
set.seed(1)
idx <- createDataPartition(yAll$signal, p = 0.1, list = F)
gc()

x <- xAll[-idx,]
y <- yAll[-idx,]
xFinalTest <- x[idx,]
yFinalTest <- y[idx,]
rm(xAll, yAll)
gc()
```

## Optimization metric

We will optimize the area under the receiver operating curve (AUC) of our models.  The AUC
is defined such that a perfect classifer has an AUC of 1 and a random classifier has an AUC of 0.5.
An advantage of using the AUC is that it reflects the trade-off between the true and false positive
rates of a model depending on the chosen classification threshold.
We will use the `pROC` package to create and plot ROC curves, and to compute their area.

<!--chapter:end:10-intro.Rmd-->

# Data analysis

In this section, we analyze the various input features of the HIGGS dataset and apply
deskewing and $z$-score normalization.

## Low-level momentum features

The input features containing `_pT`  are related to transverse (perpendicular to the input beams)
momentum, as is the high-level feature `missing_E_mag`.  Histograms of these features
are plotted as follows:

```{r Hist-momentum-features, fig.height=3.5, fig.width=7}

x |>
  select(c(contains('_pT'), 'missing_E_mag')) |>
  as.data.frame() |>
  gather() |>
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~key, scales = "free", nrow = 2) +
  ggtitle('Momentum features')
```

The momentum features are all quite skewed. To deskew the data, we apply a log transformation:

```{r Hist-momentum-features-log, fig.height=3.5, fig.width=7}

x |>
  select(c(contains('_pT'), 'missing_E_mag')) |>
  as.data.frame() |>
  log() |>
  gather() |>
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~key, scales = "free", nrow = 2) +
  ggtitle('Momentum features (log transform)')
```

The skewness of the data before and after log transformation is as follows:

```{r Skew-momentum-features}

tibble(
  Feature = x |>
    select(c(contains('_pT'), 'missing_E_mag')) |>
    as.data.table() |>
    colnames(),
  Skewness = x |>
    select(c(contains('_pT'), 'missing_E_mag')) |>
    as.data.table() |>
    as.matrix() |>
    colskewness(),
  'Skewness (log)' = x |>
    select(c(contains('_pT'), 'missing_E_mag')) |>
    as.data.table() |>
    log() |>
    as.matrix() |>
    colskewness()
) |>
  kable(align = 'lrr', booktabs = T, linesep = '')
```

## Angular features

The features containing `_eta` or `_phi` describe angular data of the detected products
of the simulated collision processes. Histograms for these features are as follows:

```{r Hist-angular-features, fig.height=5, fig.width=6}

x |>
  select(c(contains('_eta'), contains('_phi'))) |>
  as.data.frame() |>
  gather() |>
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~key, scales = "free_y", nrow = 3) +
  xlim(-pi,pi) +
  ggtitle('Angular features')
```

The histograms above do not show significant skew; therefore, deskewing will not be
applied to these input features.

## $b$-tag features

Each $b$-tag feature contains three possible values:

```{r Hist-btags, fig.height=3.5, fig.width=4}

x |>
  select(contains('_btag')) |>
  as.data.frame() |>
  gather() |>
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~key, scales = "free", nrow = 2) +
  ggtitle('b-tag features')
```

Interestingly, the $b$-tag data is encoded to have unit mean, but
not unit standard deviation:

```{r btag-means}

# b-tag means
tibble(
Mean = x |>
    select(contains('_btag')) |> 
    as.data.table() |> 
    as.matrix() |> 
    colMeans(),
'Standard Deviation' = x |>
    select(contains('_btag')) |> 
    as.data.table() |> 
    as.matrix() |> 
    colVars(std=T)
) |>
  rownames_to_column('Feature') |>
  kable(align = 'lrr', booktabs = T, linesep = '')
```


## High-level features

The high-level features for the HIGGS dataset are related to tranverse momentum and, as
with the low-level momentum features, are quite skewed:

```{r Hist-high-level-features, fig.height=5, fig.width=7}

x |>
  select(contains('m_')) |>
  as.data.frame() |>
  gather() |>
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~key, scales = "free", nrow = 3) +
  ggtitle('High-level features')
```

```{r Hist-high-level-features-log, fig.height=5, fig.width=7}

x |>
  select(contains('m_')) |>
  as.data.frame() |>
  log() |>
  gather() |>
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~key, scales = "free", nrow = 3) +
  ggtitle('High-level features (log transform)')
```

The skewness of the high-level features, before and after log transformation,
are as follows:

```{r Skew-high-level-features}

tibble(
  Feature = x |>
    select(contains('m_')) |>
    as.data.table() |>
    colnames(),
  Skewness = x |>
    select(contains('m_')) |>
    as.data.table() |>
    as.matrix() |>
    colskewness(),
  'Skewness (log)' = x |>
    select(contains('m_')) |>
    as.data.table() |>
    log() |>
    as.matrix() |>
    colskewness()
) |>
  kable(align = 'lrr', booktabs = T, linesep = '')
```

## Final data transformation

The following code applies log transformation to selected columns of the HIGGS
training dataset. We will also convert our
data types into matrices here for input into subsequent stages of our analysis:

```{r Log-transform, results='hide'}

# Apply log transform
x <- x |>
  mutate(across(
    c(contains('m_'), contains('_pT'), contains('_mag')),
    log)) |>
  as.data.table()

# Convert to matrices
x <- x %>% as.matrix()
gc()
```

The following code then scales the training data to have zero mean and unit
standard deviation:

```{r Mean-SD-scaling}

m <- colMeans(x)
sd <- colVars(x, std = T) # std=T -> compute st. dev. instead of variance
x <- scale(x, center = m, scale = sd)
```

Finally, we extract the target values to a vector:

```{r Extract-signal}

y <- y$signal
```


<!--chapter:end:20-data-analysis.Rmd-->

# `lightgbm`

We will use `lightgbm`'s implementation of the Dart algorithm for boosted regression trees with
dropouts.  The benefit of Dart compared to similar algorithms is that it avoids
over-specialization, in which later trees "tend to impact the prediction of only a few instances"
[@Vinayak2015].  The following code plots AUC against the dropout rate (i.e., the ratio of
trees dropped at each dropout) for the Dart algorithm as applied to our training data
with **3-fold validation**:

```{r lgb-drop-rate, results='hide'}

# Drop rates
dr <- c(0, 0.01, 0.02, seq(0.025, 0.07, 0.005), 0.08, 0.09, 0.1, 0.15, 0.2, 0.3, 0.5)

# Although we are not using tensorflow here, this is a convenience function
# to set multiple seeds across R and Python (i.e. reticulate)
tensorflow::set_random_seed(42, disable_gpu = F)

if (!file.exists('cache/gbm_results.RData')) {
  # Train
  gbm_scores <- sapply(dr, function(d) {
    gc()
    params <- list(
      num_threads = 32, # hardware-dependent
      boosting = "dart",
      metric = "auc",
      learning_rate = 1.0, # found to be a good value, too large leads to instability
      seed = 42, # note, any other seeds with default values take priority
      
      drop_rate = d
    )
    gbmodel <- lgb.cv(
      params, x, label = y,
      nrounds = 100, nfold = 3, obj = 'binary', verbose = 0
    )
    gbmodel$best_score
  })
  
  # Save
  save(gbm_scores, file = 'cache/gbm_results.RData')
}

load('cache/gbm_results.RData')
tensorflow::set_random_seed(42, disable_gpu = F)
```

```{r lightgbm-AUC-plot, fig.height=3, fig.width=4}

tibble(dr,gbm_scores) |>
  ggplot(aes(dr,gbm_scores)) +
  geom_line() +
  geom_point() +
  xlab('Drop rate') +
  ylab('AUC') +
  theme_gray()
```

```{r lightgbm-best-AUC}
cat('The best AUC of', max(gbm_scores),
    'is achieved with a drop rate of', dr[which.max(gbm_scores)], '.\n')
```

Note, however, that the AUC is at least 0.823 for a drop rate between 0.04 and 0.065:

```{r lightgbm-min-AUC-in-range}
  
min(gbm_scores[between(dr,0.04,0.065)])
```

## `lightgbm` model with optimized drop rate

We recompute the `lightgbm` model using the best drop rate found above:

```{r lightgbm-best-model, results='hide'}

tensorflow::set_random_seed(42, disable_gpu = F)
if (!file.exists('cache/gbm_results_2.RData')) {
  
  # Get the best drop rate from before
  best_dr <- dr[which.max(gbm_scores)]
  
  # Train the model again
  params <- list(
    num_threads = 32, # hardware-dependent
    boosting = "dart",
    metric = "auc",
    learning_rate = 1.0, # found to be a good value, too large leads to instability
    seed = 42, # note, any other seeds with default values take priority
    
    drop_rate = best_dr
  )
  gbmodel <- lgb.train(
    params, lgb.Dataset(x, label = y),
    nrounds = 100, obj = 'binary', verbose = 0
  )
  
  # Compute AUC
  auc_lgb_best <- auc(y,predict(gbmodel,x)) |> as.numeric()
  
  # Save AUC and model
  save(auc_lgb_best, gbmodel, file='cache/gbm_results_2.RData')
  cat(lgb.dump(gbmodel), file='cache/lgb_model.json') # (almost) human-readable version
}

load('cache/gbm_results_2.RData')
lgb.restore_handle(gbmodel) # if model is needed, we need to fully restore it
tensorflow::set_random_seed(42, disable_gpu = F)
```

The AUC of the model on the training set is:
```{r lightgbm-best-model-AUC}

auc_lgb_best
```

## Feature importance

The following code plots the feature importance of the ten most important features in the HIGGS
dataset, based on the trained model results:

```{r lgb-importance, fig.height=4, fig.width=4}

par(cex=0.7)
gbmodel |> lgb.importance() |> lgb.plot.importance(top_n = 10)
```

It is shown that the top five features are all "high-level" features.  However, several of the
low-level features relating to transverse momentum also appear in the top ten.  Finally, none
of the directional ('`_eta`' or '`_phi`') low-level parameters appear in the top ten important
features.

<!--chapter:end:30-lightgbm.Rmd-->

# GPU-accelerated machine learning using Keras

We will use the `keras` package for machine learning.   The `keras` package allows us
to model the data using neural networks (NN); in this case, we will use a straightforward
Multilayer Perceptron (MLP) with an Rectified Linear Unit (ReLU) activation function on
all hidden nodes and a logistic activation function on the output node, thus giving a final
estimate between 0 and 1 of the probability that a given observation corresponds to the "signal"
process.  The ReLu activation function, $\mathrm{relu}(x) = \max(0,x)$, is chosen for its
simplicity and computational efficiency.

Note that in theory, an NN with sufficient breadth can approximate any function, even with just a
single hidden layer [@Asadi2010].  However, we want a model that can learn the *general*
characteristics of the signal and background processes from which our data is obtained.
Therefore, to avoid overfitting, we withhold 20% of the training data
in each epoch for validation.  Additionally, 50% dropout is applied to each hidden layer, meaning
that only half of the hidden nodes are used in each training batch. This has also been shown to reduce
overfitting effectively [@Srivastava2014].

## Tuning the learning rate

The following code plots the binary cross-entropy (a loss metric for binary classification networks)
after each training epoch for three different learning rates, using the Adam[@Kingma2014] optimizer.
We will train networks with 3 hidden layers of 256 nodes each.

```{r Keras-history}

train_keras_history <- function(x, y, depth, breadth,
                        dropout = 0.5, learning_rate=0.0002, epochs = 50) {
  model <- keras_model_sequential()
  model |>
    layer_dense(breadth, 'relu', input_shape = ncol(x)) |>
    layer_dropout(rate = dropout)
  
  # subsequent hidden layers
  if (depth > 1) {
    for (layer in seq(2,depth)) {
      model |> layer_dense(breadth, 'relu') |> layer_dropout(rate = dropout)
    }
  }
  
  # output layer (logistic activation function for binary classification)
  model |> layer_dense(1, 'sigmoid')
  
  # compile model
  model |>
    keras::compile(
      loss = 'binary_crossentropy',
      optimizer = optimizer_adam(learning_rate = learning_rate),
      metrics = metric_auc()
    )
  
  # a larger batch size trains faster but uses more GPU memory
  history <- model |>
    fit(x, y, epochs = epochs, batch_size = 8192, validation_split = 0.2)
  
  rm(model)
  gc()
  k_clear_session()
  tensorflow::tf$compat$v1$reset_default_graph()
  
  history
}
```

```{r Keras-learning-rate-effect, results='hide'}
tensorflow::set_random_seed(42, disable_gpu = F)
if (!file.exists('cache/nn_results.RDdata')) {
  history1 <- train_keras_history(x, y, 3, 256, learning_rate = 1e-3)
  history2 <- train_keras_history(x, y, 3, 256, learning_rate = 5e-4)
  history3 <- train_keras_history(x, y, 3, 256, learning_rate = 2e-4)
  save(history1, history2, history3, file = 'cache/nn_results.RDdata')
}
load('cache/nn_results.RDdata')
tensorflow::set_random_seed(42, disable_gpu = F)
```

```{r fig.height=3, fig.width=5}
tibble(
  epoch = seq(50),
  `1e-3` = history1$metrics$val_loss,
  `5e-4` = history2$metrics$val_loss,
  `2e-4` = history3$metrics$val_loss) |>
  pivot_longer(-epoch,'lr',values_to = 'loss') |>
  mutate(lr = as.numeric(lr)) |> 
  ggplot(aes(epoch,loss, color=as.factor(lr))) +
  geom_line() +
  xlab('Epochs') +
  ylab('Binary cross-entropy') +
  labs(color='Learning Rate')
```

The results show that a smaller learning rate provides smoother loss as a function of the
number of training epochs, but takes longer to train. Nevertheless, even the lowest learning
rate shown above results in reasonably fast convergence. On the other hand, a learning rate that is
too large may lead to non-convergence of the loss function. Based on the above results,
we will use a training rate of $2\times10^{-4}$ for all subsequent modelling.

## Effect of MLP depth and breadth

The following function trains an MLP with the specified
number of hidden layers (`depth`) and nodes per hidden layer (`breadth`),
and returns the model and training history.
We will use the Adam[@Kingma2014] optimizer with a learning rate of $2\times 10^{-4}$ and 50 epochs.

```{r Keras-tuning-function}

# Tuning values given defaults are not included in our parameter search for this
# project.
train_keras_auc <- function(x, y,
                        depth, breadth,
                        dropout = 0.5, learning_rate = 0.0002,
                        epochs = 50) {
  cat('DNN: ', depth, 'x', breadth, '\n')
  
  model <- keras_model_sequential()
  
  # By default, Keras applies Glorot uniform initialization for weights
  # and zero initialization for biases. Glorot uniform initialization
  # samples weights from Uniform(-sqrt(6/n),sqrt(6/n)) where n is the
  # sum of in and out nodes between two input/hidden/output layers.
  
  # first hidden layer
  model |>
    layer_dense(units = breadth,
                activation = 'relu',
                input_shape = ncol(x)) |>
    layer_dropout(rate = dropout)
  
  # subsequent hidden layers
  if (depth > 1) {
    for (layer in seq(2,depth)) {
      model |>
        layer_dense(units = breadth, activation = 'relu') |>
        layer_dropout(rate = dropout)
    }
  }
  
  # output layer (logistic activation function for binary classification)
  model |>
    layer_dense(units = 1, activation = 'sigmoid')
  
  # compile model
  model |>
    keras::compile(
      loss = 'binary_crossentropy',
      optimizer = optimizer_adam(learning_rate = learning_rate),
      metrics = metric_auc()
    )
  
  # a larger batch size trains faster but uses more GPU memory
  history <- model |>
    fit(x, y,
        epochs = epochs, batch_size = 8192,
        validation_split = 0.2)
  
  ypred <- model |> predict(x, batch_size = 8192) |> as.vector()
  auc <- roc(y,ypred) |> auc() |> as.numeric()
  
  rm(model)
  gc()
  k_clear_session()
  tensorflow::tf$compat$v1$reset_default_graph()
  
  auc
}
```

The following code computes and plots the AUC for NNs with 1 to 5 hidden layers and
from 16 to 2048 hidden nodes in each hidden layer:

```{r Keras-tuning-run, results='hide'}

# Try NN training for different NN depths and breadths.  Cache using .RData file.
tensorflow::set_random_seed(42, disable_gpu = F)
if (!file.exists('cache/nn_results2.RDdata')) {
  nn_results <- tibble(depth = integer(), breadth = integer(), auc = numeric())
  
  for(l in 1:5) { # depth: number of hidden layers
    for (n in 2^c(5:11)) { # breadth: hidden nodes per layer
      nn_results <- nn_results |>
        add_row(depth = l,
                breadth = n,
                auc = train_keras_auc(x, y, l, n))
    }
  }
  save(nn_results, file = 'cache/nn_results2.RDdata')
}
load('cache/nn_results2.RDdata')
tensorflow::set_random_seed(42, disable_gpu = F)
```

```{r Keras-tuning-plot, fig.height=3.5, fig.width=4.5}

# heatmap of AUC vs depth and breadth
nn_results |> ggplot(aes(as.factor(depth), as.factor(breadth), fill = auc)) +
  geom_tile() +
  geom_text(aes(label = round(auc,4)), color = "black", size = 3) +
  scale_fill_viridis_c() +
  xlab('Depth (number of hidden layers)') +
  ylab('Breadth (hidden nodes per layer)')
```

The results show that for NNs with at least 64 nodes per hidden layer, there is little difference
between having three layers or more; however, there is a slight advantage to having three hidden
layers compared to two.  In all cases, the widest NN at each depth provides the best AUC.
Therefore, the 3x2048 NN appears to provide the best trade-off between network complexity and AUC.
If memory or compute resources are limited, a 2x512 NN also appears to give reasonable estimation
power.

## Dropping high-level features

Since the high-level features in the HIGGS dataset are derived from the other, low-level features,
it is clear that a good model should be able to learn the data without use of these features.
The following code trains a 3x20484 NN on the HIGGS dataset once using all features and once
just the low-level features:

```{r train-keras, eval=FALSE, include=FALSE}

train_keras <- function(x, y,
                        depth, breadth,
                        dropout = 0.5, learning_rate = 0.0002,
                        epochs = 50) {
  
  model <- keras_model_sequential()
  
  # first hidden layer
  model |>
    layer_dense(units = breadth,
                activation = 'relu',
                input_shape = ncol(x)) |>
    layer_dropout(rate = dropout)
  
  # subsequent hidden layers
  if (depth > 1) {
    for (layer in seq(2,depth)) {
      model |>
        layer_dense(units = breadth, activation = 'relu') |>
        layer_dropout(rate = dropout)
    }
  }
  
  # output layer (logistic activation function for binary classification)
  model |>
    layer_dense(units = 1, activation = 'sigmoid')
  
  # compile model
  model |>
    keras::compile(
      loss = 'binary_crossentropy',
      optimizer = optimizer_adam(learning_rate = learning_rate),
      metrics = metric_auc()
    )
  
  # a larger batch size trains faster but uses more GPU memory
  model |>
    fit(x, y,
        epochs = epochs, batch_size = 8192,
        validation_split = 0.2)
}

tensorflow::set_random_seed(42, disable_gpu = F)
if (!file.exists('cache/nn_results3.RDdata')) {
  model_full <- train_keras(x, y, 3, 2048, learning_rate = 2e-4)
  model_low_only <- train_keras(x[,1:21], y, 3, 2048, learning_rate = 2e-4)
  save(history4, history5, file='cache/nn_results3.RDdata')
}
load('cache/nn_results3.RDdata')
tensorflow::set_random_seed(42, disable_gpu = F)
```

The following code computes and prints the AUC for the both models:

<!--chapter:end:40-keras.Rmd-->

# Final model selection and validation

<!--chapter:end:80-validation.Rmd-->

# References {-}

<div id="refs"></div>

<!--chapter:end:91-references.Rmd-->

