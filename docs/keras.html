<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 GPU-accelerated machine learning using Keras | HarvardX 125.9x Project: Higgs dataset classification</title>
  <meta name="description" content="See also: _output.yml, _bookdown.yml" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 GPU-accelerated machine learning using Keras | HarvardX 125.9x Project: Higgs dataset classification" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="See also: _output.yml, _bookdown.yml" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 GPU-accelerated machine learning using Keras | HarvardX 125.9x Project: Higgs dataset classification" />
  
  <meta name="twitter:description" content="See also: _output.yml, _bookdown.yml" />
  

<meta name="author" content="Yin-Chi Chan" />


<meta name="date" content="2022-10-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-analysis-and-transformation.html"/>
<link rel="next" href="final-model-selection-and-validation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">HarvardX 125.9: Higgs data analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#r-setup"><i class="fa fa-check"></i><b>0.1</b> R setup</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#the-higgs-dataset"><i class="fa fa-check"></i><b>1.1</b> The HIGGS dataset</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#creating-the-final-test-splits"><i class="fa fa-check"></i><b>1.2</b> Creating the final test splits</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#optimization-metric"><i class="fa fa-check"></i><b>1.3</b> Optimization metric</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-analysis-and-transformation.html"><a href="data-analysis-and-transformation.html"><i class="fa fa-check"></i><b>2</b> Data analysis and transformation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-analysis-and-transformation.html"><a href="data-analysis-and-transformation.html#momentum-features"><i class="fa fa-check"></i><b>2.1</b> Momentum features</a></li>
<li class="chapter" data-level="2.2" data-path="data-analysis-and-transformation.html"><a href="data-analysis-and-transformation.html#angular-features"><i class="fa fa-check"></i><b>2.2</b> Angular features</a></li>
<li class="chapter" data-level="2.3" data-path="data-analysis-and-transformation.html"><a href="data-analysis-and-transformation.html#b-tag-features"><i class="fa fa-check"></i><b>2.3</b> <span class="math inline">\(b\)</span>-tag features</a></li>
<li class="chapter" data-level="2.4" data-path="data-analysis-and-transformation.html"><a href="data-analysis-and-transformation.html#high-level-features"><i class="fa fa-check"></i><b>2.4</b> High-level features</a></li>
<li class="chapter" data-level="2.5" data-path="data-analysis-and-transformation.html"><a href="data-analysis-and-transformation.html#final-data-transformation"><i class="fa fa-check"></i><b>2.5</b> Final data transformation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="keras.html"><a href="keras.html"><i class="fa fa-check"></i><b>3</b> GPU-accelerated machine learning using Keras</a>
<ul>
<li class="chapter" data-level="3.1" data-path="keras.html"><a href="keras.html#tuning-the-learning-rate"><i class="fa fa-check"></i><b>3.1</b> Tuning the learning rate</a></li>
<li class="chapter" data-level="3.2" data-path="keras.html"><a href="keras.html#effect-of-mlp-depth-and-breadth"><i class="fa fa-check"></i><b>3.2</b> Effect of MLP depth and breadth</a></li>
<li class="chapter" data-level="3.3" data-path="keras.html"><a href="keras.html#dropping-high-level-features"><i class="fa fa-check"></i><b>3.3</b> Dropping high-level features</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="final-model-selection-and-validation.html"><a href="final-model-selection-and-validation.html"><i class="fa fa-check"></i><b>4</b> Final model selection and validation</a></li>
<li class="chapter" data-level="5" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>5</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/yinchi/harvardx-higgs" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">HarvardX 125.9x Project: Higgs dataset classification</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="keras" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> GPU-accelerated machine learning using Keras<a href="keras.html#keras" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>We will use the <code>keras</code> package for machine learning. The <code>keras</code> package allows us
to model the data using neural networks (NN); in this case, we will use a straightforward
Multilayer Perceptron (MLP) with an Rectified Linear Unit (ReLU) activation function on
all hidden nodes and a logistic activation function on the output node, thus giving a final
estimate between 0 and 1 of the probability that a given observation corresponds to the “signal”
process. The ReLu activation function, <span class="math inline">\(\mathrm{relu}(x) = \max(0,x)\)</span>, is chosen for its
simplicity and computational efficiency.</p>
<p>Note that in theory, an NN with sufficient breadth can approximate any function, even with just a
single hidden layer <span class="citation">(<a href="#ref-Asadi2010" role="doc-biblioref">Asadi and Jiang 2020</a>)</span>. However, we want a model that can learn the <em>general</em>
characteristics of the signal and background processes from which our data is obtained.
Therefore, to avoid overfitting, we withhold 20% of the training data
in each epoch for validation. Additionally, 50% dropout is applied to each hidden layer, meaning
that only half of the hidden nodes are used in each training batch. This has also been shown to reduce
overfitting effectively <span class="citation">(<a href="#ref-Srivastava2014" role="doc-biblioref">Srivastava et al. 2014</a>)</span>.</p>
<div id="tuning-the-learning-rate" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Tuning the learning rate<a href="keras.html#tuning-the-learning-rate" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The following code plots the binary cross-entropy (a loss metric for binary classification networks)
after each training epoch for three different learning rates, using the Adam <span class="citation">(<a href="#ref-Kingma2014" role="doc-biblioref">Kingma and Ba 2014</a>)</span> optimizer.
We will train networks with 3 hidden layers of 256 nodes each.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="keras.html#cb17-1" aria-hidden="true" tabindex="-1"></a>train_keras_history <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y, depth, breadth,</span>
<span id="cb17-2"><a href="keras.html#cb17-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">dropout =</span> <span class="fl">0.5</span>, <span class="at">learning_rate=</span><span class="fl">0.0002</span>, <span class="at">epochs =</span> <span class="dv">50</span>) {</span>
<span id="cb17-3"><a href="keras.html#cb17-3" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>(<span class="at">input_shape =</span> <span class="fu">ncol</span>(x))</span>
<span id="cb17-4"><a href="keras.html#cb17-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-5"><a href="keras.html#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Hidden layers</span></span>
<span id="cb17-6"><a href="keras.html#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (layer <span class="cf">in</span> <span class="fu">seq</span>(depth)) {</span>
<span id="cb17-7"><a href="keras.html#cb17-7" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">|&gt;</span> <span class="fu">layer_dense</span>(breadth, <span class="st">&#39;relu&#39;</span>) <span class="sc">|&gt;</span> <span class="fu">layer_dropout</span>(<span class="at">rate =</span> dropout)</span>
<span id="cb17-8"><a href="keras.html#cb17-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb17-9"><a href="keras.html#cb17-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-10"><a href="keras.html#cb17-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Output layer (logistic activation function for binary classification)</span></span>
<span id="cb17-11"><a href="keras.html#cb17-11" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">|&gt;</span> <span class="fu">layer_dense</span>(<span class="dv">1</span>, <span class="st">&#39;sigmoid&#39;</span>)</span>
<span id="cb17-12"><a href="keras.html#cb17-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-13"><a href="keras.html#cb17-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compile model</span></span>
<span id="cb17-14"><a href="keras.html#cb17-14" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">|&gt;</span></span>
<span id="cb17-15"><a href="keras.html#cb17-15" aria-hidden="true" tabindex="-1"></a>    keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb17-16"><a href="keras.html#cb17-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">loss =</span> <span class="st">&#39;binary_crossentropy&#39;</span>,</span>
<span id="cb17-17"><a href="keras.html#cb17-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(<span class="at">learning_rate =</span> learning_rate),</span>
<span id="cb17-18"><a href="keras.html#cb17-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> <span class="fu">metric_auc</span>()</span>
<span id="cb17-19"><a href="keras.html#cb17-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-20"><a href="keras.html#cb17-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-21"><a href="keras.html#cb17-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># A larger batch size trains faster but uses more GPU memory</span></span>
<span id="cb17-22"><a href="keras.html#cb17-22" aria-hidden="true" tabindex="-1"></a>  history <span class="ot">&lt;-</span> model <span class="sc">|&gt;</span></span>
<span id="cb17-23"><a href="keras.html#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(x, y, <span class="at">epochs =</span> epochs, <span class="at">batch_size =</span> <span class="dv">8192</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb17-24"><a href="keras.html#cb17-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-25"><a href="keras.html#cb17-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Clean-up</span></span>
<span id="cb17-26"><a href="keras.html#cb17-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rm</span>(model)</span>
<span id="cb17-27"><a href="keras.html#cb17-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gc</span>()</span>
<span id="cb17-28"><a href="keras.html#cb17-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">k_clear_session</span>()</span>
<span id="cb17-29"><a href="keras.html#cb17-29" aria-hidden="true" tabindex="-1"></a>  tensorflow<span class="sc">::</span>tf<span class="sc">$</span>compat<span class="sc">$</span>v1<span class="sc">$</span><span class="fu">reset_default_graph</span>()</span>
<span id="cb17-30"><a href="keras.html#cb17-30" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-31"><a href="keras.html#cb17-31" aria-hidden="true" tabindex="-1"></a>  history</span>
<span id="cb17-32"><a href="keras.html#cb17-32" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="keras.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a 3x256 NN with three different learning rates</span></span>
<span id="cb18-2"><a href="keras.html#cb18-2" aria-hidden="true" tabindex="-1"></a>tensorflow<span class="sc">::</span><span class="fu">set_random_seed</span>(<span class="dv">42</span>, <span class="at">disable_gpu =</span> F)</span>
<span id="cb18-3"><a href="keras.html#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">file.exists</span>(<span class="st">&#39;cache/nn_results.RDdata&#39;</span>)) {</span>
<span id="cb18-4"><a href="keras.html#cb18-4" aria-hidden="true" tabindex="-1"></a>  history1 <span class="ot">&lt;-</span> <span class="fu">train_keras_history</span>(x, y, <span class="dv">3</span>, <span class="dv">256</span>, <span class="at">learning_rate =</span> <span class="fl">1e-3</span>)</span>
<span id="cb18-5"><a href="keras.html#cb18-5" aria-hidden="true" tabindex="-1"></a>  history2 <span class="ot">&lt;-</span> <span class="fu">train_keras_history</span>(x, y, <span class="dv">3</span>, <span class="dv">256</span>, <span class="at">learning_rate =</span> <span class="fl">5e-4</span>)</span>
<span id="cb18-6"><a href="keras.html#cb18-6" aria-hidden="true" tabindex="-1"></a>  history3 <span class="ot">&lt;-</span> <span class="fu">train_keras_history</span>(x, y, <span class="dv">3</span>, <span class="dv">256</span>, <span class="at">learning_rate =</span> <span class="fl">2e-4</span>)</span>
<span id="cb18-7"><a href="keras.html#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">save</span>(history1, history2, history3, <span class="at">file =</span> <span class="st">&#39;cache/nn_results.RDdata&#39;</span>)</span>
<span id="cb18-8"><a href="keras.html#cb18-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-9"><a href="keras.html#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&#39;cache/nn_results.RDdata&#39;</span>)</span>
<span id="cb18-10"><a href="keras.html#cb18-10" aria-hidden="true" tabindex="-1"></a>tensorflow<span class="sc">::</span><span class="fu">set_random_seed</span>(<span class="dv">42</span>, <span class="at">disable_gpu =</span> F)</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="keras.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot metric over the number of epochs</span></span>
<span id="cb19-2"><a href="keras.html#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb19-3"><a href="keras.html#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">epoch =</span> <span class="fu">seq</span>(<span class="dv">50</span>),</span>
<span id="cb19-4"><a href="keras.html#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">1e-3</span><span class="st">`</span> <span class="ot">=</span> history1<span class="sc">$</span>metrics<span class="sc">$</span>val_loss,</span>
<span id="cb19-5"><a href="keras.html#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">5e-4</span><span class="st">`</span> <span class="ot">=</span> history2<span class="sc">$</span>metrics<span class="sc">$</span>val_loss,</span>
<span id="cb19-6"><a href="keras.html#cb19-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">2e-4</span><span class="st">`</span> <span class="ot">=</span> history3<span class="sc">$</span>metrics<span class="sc">$</span>val_loss</span>
<span id="cb19-7"><a href="keras.html#cb19-7" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span></span>
<span id="cb19-8"><a href="keras.html#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>epoch,<span class="st">&#39;lr&#39;</span>,<span class="at">values_to =</span> <span class="st">&#39;loss&#39;</span>) <span class="sc">|&gt;</span></span>
<span id="cb19-9"><a href="keras.html#cb19-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">lr =</span> <span class="fu">as.numeric</span>(lr)) <span class="sc">|&gt;</span></span>
<span id="cb19-10"><a href="keras.html#cb19-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(epoch,loss, <span class="at">color=</span><span class="fu">as.factor</span>(lr))) <span class="sc">+</span></span>
<span id="cb19-11"><a href="keras.html#cb19-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb19-12"><a href="keras.html#cb19-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&#39;Epochs&#39;</span>) <span class="sc">+</span></span>
<span id="cb19-13"><a href="keras.html#cb19-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&#39;Binary cross-entropy&#39;</span>) <span class="sc">+</span></span>
<span id="cb19-14"><a href="keras.html#cb19-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color=</span><span class="st">&#39;Learning Rate&#39;</span>)</span></code></pre></div>
<p><img src="higgs_files/figure-html/Keras-learning-rate-plot-1.png" width="720" /></p>
<p>The results show that a smaller learning rate provides smoother loss as a function of the
number of training epochs, but takes longer to train. Nevertheless, even the lowest learning
rate shown above results in reasonably fast convergence. On the other hand, a learning rate that is
too large may lead to non-convergence of the loss function. Based on the above results,
we will use a training rate of <span class="math inline">\(2\times10^{-4}\)</span> for all subsequent modelling.</p>
</div>
<div id="effect-of-mlp-depth-and-breadth" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Effect of MLP depth and breadth<a href="keras.html#effect-of-mlp-depth-and-breadth" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The following function trains an MLP with the specified
number of hidden layers (<code>depth</code>) and nodes per hidden layer (<code>breadth</code>),
and returns the model and training history.
We will use the Adam <span class="citation">(<a href="#ref-Kingma2014" role="doc-biblioref">Kingma and Ba 2014</a>)</span> optimizer with a learning rate of <span class="math inline">\(2\times 10^{-4}\)</span> and 50 epochs.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="keras.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tuning values given defaults are not included in our parameter search for this</span></span>
<span id="cb20-2"><a href="keras.html#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># project.</span></span>
<span id="cb20-3"><a href="keras.html#cb20-3" aria-hidden="true" tabindex="-1"></a>train_keras_auc <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y,</span>
<span id="cb20-4"><a href="keras.html#cb20-4" aria-hidden="true" tabindex="-1"></a>                        depth, breadth,</span>
<span id="cb20-5"><a href="keras.html#cb20-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">dropout =</span> <span class="fl">0.5</span>, <span class="at">learning_rate =</span> <span class="fl">0.0002</span>,</span>
<span id="cb20-6"><a href="keras.html#cb20-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">epochs =</span> <span class="dv">50</span>) {</span>
<span id="cb20-7"><a href="keras.html#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&#39;DNN: &#39;</span>, depth, <span class="st">&#39;x&#39;</span>, breadth, <span class="st">&#39;</span><span class="sc">\n</span><span class="st">&#39;</span>)</span>
<span id="cb20-8"><a href="keras.html#cb20-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-9"><a href="keras.html#cb20-9" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>(<span class="at">input_shape =</span> <span class="fu">ncol</span>(x))</span>
<span id="cb20-10"><a href="keras.html#cb20-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-11"><a href="keras.html#cb20-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># By default, Keras applies Glorot uniform initialization for weights</span></span>
<span id="cb20-12"><a href="keras.html#cb20-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># and zero initialization for biases. Glorot uniform initialization</span></span>
<span id="cb20-13"><a href="keras.html#cb20-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># samples weights from Uniform(-sqrt(6/n),sqrt(6/n)) where n is the</span></span>
<span id="cb20-14"><a href="keras.html#cb20-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sum of in and out nodes between two input/hidden/output layers.</span></span>
<span id="cb20-15"><a href="keras.html#cb20-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-16"><a href="keras.html#cb20-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Hidden layers</span></span>
<span id="cb20-17"><a href="keras.html#cb20-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (layer <span class="cf">in</span> <span class="fu">seq</span>(depth)) {</span>
<span id="cb20-18"><a href="keras.html#cb20-18" aria-hidden="true" tabindex="-1"></a>    model <span class="sc">|&gt;</span> <span class="fu">layer_dense</span>(breadth, <span class="st">&#39;relu&#39;</span>) <span class="sc">|&gt;</span> <span class="fu">layer_dropout</span>(<span class="at">rate =</span> dropout)</span>
<span id="cb20-19"><a href="keras.html#cb20-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb20-20"><a href="keras.html#cb20-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-21"><a href="keras.html#cb20-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Output layer (logistic activation function for binary classification)</span></span>
<span id="cb20-22"><a href="keras.html#cb20-22" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">|&gt;</span></span>
<span id="cb20-23"><a href="keras.html#cb20-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>, <span class="at">activation =</span> <span class="st">&#39;sigmoid&#39;</span>)</span>
<span id="cb20-24"><a href="keras.html#cb20-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-25"><a href="keras.html#cb20-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compile model</span></span>
<span id="cb20-26"><a href="keras.html#cb20-26" aria-hidden="true" tabindex="-1"></a>  model <span class="sc">|&gt;</span></span>
<span id="cb20-27"><a href="keras.html#cb20-27" aria-hidden="true" tabindex="-1"></a>    keras<span class="sc">::</span><span class="fu">compile</span>(</span>
<span id="cb20-28"><a href="keras.html#cb20-28" aria-hidden="true" tabindex="-1"></a>      <span class="at">loss =</span> <span class="st">&#39;binary_crossentropy&#39;</span>,</span>
<span id="cb20-29"><a href="keras.html#cb20-29" aria-hidden="true" tabindex="-1"></a>      <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(<span class="at">learning_rate =</span> learning_rate),</span>
<span id="cb20-30"><a href="keras.html#cb20-30" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> <span class="fu">metric_auc</span>()</span>
<span id="cb20-31"><a href="keras.html#cb20-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-32"><a href="keras.html#cb20-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-33"><a href="keras.html#cb20-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># A larger batch size trains faster but uses more GPU memory</span></span>
<span id="cb20-34"><a href="keras.html#cb20-34" aria-hidden="true" tabindex="-1"></a>  history <span class="ot">&lt;-</span> model <span class="sc">|&gt;</span></span>
<span id="cb20-35"><a href="keras.html#cb20-35" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(x, y, <span class="at">epochs =</span> epochs, <span class="at">batch_size =</span> <span class="dv">8192</span>, <span class="at">validation_split =</span> <span class="fl">0.2</span>)</span>
<span id="cb20-36"><a href="keras.html#cb20-36" aria-hidden="true" tabindex="-1"></a>  ypred <span class="ot">&lt;-</span> model <span class="sc">|&gt;</span> <span class="fu">predict</span>(x, <span class="at">batch_size =</span> <span class="dv">8192</span>) <span class="sc">|&gt;</span> <span class="fu">as.vector</span>()</span>
<span id="cb20-37"><a href="keras.html#cb20-37" aria-hidden="true" tabindex="-1"></a>  auc <span class="ot">&lt;-</span> <span class="fu">roc</span>(y,ypred) <span class="sc">|&gt;</span> <span class="fu">auc</span>() <span class="sc">|&gt;</span> <span class="fu">as.numeric</span>()</span>
<span id="cb20-38"><a href="keras.html#cb20-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-39"><a href="keras.html#cb20-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rm</span>(model)</span>
<span id="cb20-40"><a href="keras.html#cb20-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gc</span>()</span>
<span id="cb20-41"><a href="keras.html#cb20-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">k_clear_session</span>()</span>
<span id="cb20-42"><a href="keras.html#cb20-42" aria-hidden="true" tabindex="-1"></a>  tensorflow<span class="sc">::</span>tf<span class="sc">$</span>compat<span class="sc">$</span>v1<span class="sc">$</span><span class="fu">reset_default_graph</span>()</span>
<span id="cb20-43"><a href="keras.html#cb20-43" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-44"><a href="keras.html#cb20-44" aria-hidden="true" tabindex="-1"></a>  auc</span>
<span id="cb20-45"><a href="keras.html#cb20-45" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The following code computes and plots the AUC for NNs with 1 to 5 hidden layers and
from 16 to 2048 hidden nodes in each hidden layer:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="keras.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try NN training for different NN depths and breadths.  Cache using .RData file.</span></span>
<span id="cb21-2"><a href="keras.html#cb21-2" aria-hidden="true" tabindex="-1"></a>tensorflow<span class="sc">::</span><span class="fu">set_random_seed</span>(<span class="dv">42</span>, <span class="at">disable_gpu =</span> F)</span>
<span id="cb21-3"><a href="keras.html#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">file.exists</span>(<span class="st">&#39;cache/nn_results2.RDdata&#39;</span>)) {</span>
<span id="cb21-4"><a href="keras.html#cb21-4" aria-hidden="true" tabindex="-1"></a>  nn_results <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">depth =</span> <span class="fu">integer</span>(), <span class="at">breadth =</span> <span class="fu">integer</span>(), <span class="at">auc =</span> <span class="fu">numeric</span>())</span>
<span id="cb21-5"><a href="keras.html#cb21-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-6"><a href="keras.html#cb21-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(l <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>) { <span class="co"># depth: number of hidden layers</span></span>
<span id="cb21-7"><a href="keras.html#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">2</span><span class="sc">^</span><span class="fu">c</span>(<span class="dv">5</span><span class="sc">:</span><span class="dv">11</span>)) { <span class="co"># breadth: hidden nodes per layer</span></span>
<span id="cb21-8"><a href="keras.html#cb21-8" aria-hidden="true" tabindex="-1"></a>      nn_results <span class="ot">&lt;-</span> nn_results <span class="sc">|&gt;</span></span>
<span id="cb21-9"><a href="keras.html#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">add_row</span>(<span class="at">depth =</span> l, <span class="at">breadth =</span> n, <span class="at">auc =</span> <span class="fu">train_keras_auc</span>(x, y, l, n))</span>
<span id="cb21-10"><a href="keras.html#cb21-10" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb21-11"><a href="keras.html#cb21-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb21-12"><a href="keras.html#cb21-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">save</span>(nn_results, <span class="at">file =</span> <span class="st">&#39;cache/nn_results2.RDdata&#39;</span>)</span>
<span id="cb21-13"><a href="keras.html#cb21-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-14"><a href="keras.html#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&#39;cache/nn_results2.RDdata&#39;</span>)</span>
<span id="cb21-15"><a href="keras.html#cb21-15" aria-hidden="true" tabindex="-1"></a>tensorflow<span class="sc">::</span><span class="fu">set_random_seed</span>(<span class="dv">42</span>, <span class="at">disable_gpu =</span> F)</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="keras.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Heatmap of AUC vs depth and breadth</span></span>
<span id="cb22-2"><a href="keras.html#cb22-2" aria-hidden="true" tabindex="-1"></a>nn_results <span class="sc">|&gt;</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="fu">as.factor</span>(depth), <span class="fu">as.factor</span>(breadth), <span class="at">fill =</span> auc)) <span class="sc">+</span></span>
<span id="cb22-3"><a href="keras.html#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>() <span class="sc">+</span></span>
<span id="cb22-4"><a href="keras.html#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">round</span>(auc,<span class="dv">4</span>)), <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb22-5"><a href="keras.html#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_viridis_c</span>() <span class="sc">+</span></span>
<span id="cb22-6"><a href="keras.html#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&#39;Depth (number of hidden layers)&#39;</span>) <span class="sc">+</span></span>
<span id="cb22-7"><a href="keras.html#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&#39;Breadth (hidden nodes per layer)&#39;</span>)</span></code></pre></div>
<p><img src="higgs_files/figure-html/Keras-tuning-plot-1.png" width="648" /></p>
<p>The results show that for NNs with at least 64 nodes per hidden layer, there is little difference
between having three layers or more; however, there is a slight advantage to having three hidden
layers compared to two. In all cases, the widest NN at each depth provides the best AUC.
Therefore, the 3x2048 NN appears to provide the best trade-off between network complexity and AUC.
If memory or compute resources are limited, a 2x512 NN also appears to give reasonable estimation
power.</p>
</div>
<div id="dropping-high-level-features" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Dropping high-level features<a href="keras.html#dropping-high-level-features" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Since the high-level features in the HIGGS dataset are derived from the other, low-level features,
it is clear that a good model should be able to learn the data without use of these features.
The following code trains a 3x2048 NN on the HIGGS using
just the low-level features:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="keras.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train 3x2048 NN using low-level features only.  Cache the AUC value.</span></span>
<span id="cb23-2"><a href="keras.html#cb23-2" aria-hidden="true" tabindex="-1"></a>tensorflow<span class="sc">::</span><span class="fu">set_random_seed</span>(<span class="dv">42</span>, <span class="at">disable_gpu =</span> F)</span>
<span id="cb23-3"><a href="keras.html#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">file.exists</span>(<span class="st">&#39;cache/nn_results3.RDdata&#39;</span>)) {</span>
<span id="cb23-4"><a href="keras.html#cb23-4" aria-hidden="true" tabindex="-1"></a>  auc_low_only <span class="ot">&lt;-</span> <span class="fu">train_keras_auc</span>(x[,<span class="dv">1</span><span class="sc">:</span><span class="dv">21</span>], y, <span class="dv">3</span>, <span class="dv">2048</span>, <span class="at">learning_rate =</span> <span class="fl">2e-4</span>)</span>
<span id="cb23-5"><a href="keras.html#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">save</span>(auc_low_only, <span class="at">file=</span><span class="st">&#39;cache/nn_results3.RDdata&#39;</span>)</span>
<span id="cb23-6"><a href="keras.html#cb23-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-7"><a href="keras.html#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">&#39;cache/nn_results3.RDdata&#39;</span>)</span>
<span id="cb23-8"><a href="keras.html#cb23-8" aria-hidden="true" tabindex="-1"></a>tensorflow<span class="sc">::</span><span class="fu">set_random_seed</span>(<span class="dv">42</span>, <span class="at">disable_gpu =</span> F)</span></code></pre></div>
<p>The following code displays the AUC for the 3x2048 NN with and without the high-level features:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="keras.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb24-2"><a href="keras.html#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">Features =</span> <span class="fu">c</span>(<span class="st">&#39;All&#39;</span>, <span class="st">&#39;Low-level only&#39;</span>),</span>
<span id="cb24-3"><a href="keras.html#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">AUC =</span> <span class="fu">c</span>(</span>
<span id="cb24-4"><a href="keras.html#cb24-4" aria-hidden="true" tabindex="-1"></a>    nn_results <span class="sc">|&gt;</span> <span class="fu">filter</span>(breadth <span class="sc">==</span> <span class="dv">2048</span> <span class="sc">&amp;</span> depth <span class="sc">==</span> <span class="dv">3</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(auc),</span>
<span id="cb24-5"><a href="keras.html#cb24-5" aria-hidden="true" tabindex="-1"></a>    auc_low_only</span>
<span id="cb24-6"><a href="keras.html#cb24-6" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb24-7"><a href="keras.html#cb24-7" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> <span class="fu">kable</span>(<span class="at">align =</span> <span class="st">&#39;lr&#39;</span>, <span class="at">booktabs =</span> T, <span class="at">linesep =</span> <span class="st">&#39;&#39;</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Features</th>
<th align="right">AUC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">All</td>
<td align="right">0.8766273</td>
</tr>
<tr class="even">
<td align="left">Low-level only</td>
<td align="right">0.8663024</td>
</tr>
</tbody>
</table>
<p>The AUC for the low-level-only NN is only slightly lower than that for
the full network, demonstrating that the NN is able to learn the complex
non-linear relationships between the independent and dependent
variables on it its own without the need for additional derived variables.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Asadi2010" class="csl-entry">
Asadi, Behnam, and Hui Jiang. 2020. <span>“On Approximation Capabilities of ReLU Activation and Softmax Output Layer in Neural Networks.”</span> <a href="https://doi.org/10.48550/arXiv.2002.04060">https://doi.org/10.48550/arXiv.2002.04060</a>.
</div>
<div id="ref-Kingma2014" class="csl-entry">
Kingma, Diederik P., and Jimmy Ba. 2014. <span>“Adam: A Method for Stochastic Optimization.”</span> <a href="https://doi.org/10.48550/arXiv.1412.6980">https://doi.org/10.48550/arXiv.1412.6980</a>.
</div>
<div id="ref-Srivastava2014" class="csl-entry">
Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. <span>“Dropout: A Simple Way to Prevent Neural Networks from Overfitting.”</span> <em>Journal of Machine Learning Research</em> 15 (56): 1929–58. <a href="http://jmlr.org/papers/v15/srivastava14a.html">http://jmlr.org/papers/v15/srivastava14a.html</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-analysis-and-transformation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="final-model-selection-and-validation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin"]
},
"fontsettings": {
"theme": "sepia",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/yinchi/harvardx-higgs/blob/main/40-keras.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["higgs.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
